{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYlXgDEdwXzm"
      },
      "source": [
        "# Graded Challenge 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhEEiUlswkwh"
      },
      "source": [
        "Nama: Wilona Natalie Elvaretta  \n",
        "Batch: RMT-028  \n",
        "Dataset: [Kaggle](https://www.kaggle.com/datasets/guru001/movie-genre-prediction/data?select=sample_submission.csv)  \n",
        "Deployment: [HuggingFace](https://huggingface.co/spaces/wilonatalie/p2-ftds028-rmt-g7)  \n",
        "Model: [NLP](https://drive.google.com/drive/folders/1rWdKxgfGYNyhlGdIW2Au5yn37EwFHBip?usp=sharing)\n",
        "  \n",
        "**Problem**:  \n",
        "Movie genre classification berguna untuk banyak hal, beberapa di antaranya sebagai berikut:\n",
        "- Filmmaker bisa menguji apakah sinopsis yang mereka draft bisa dikategorikan sebagai genre yang dikehendaki. Jika prediksi tepat, penonton akan mudah untuk menangkap genre film yang ditawarkan hanya dengan membaca sinopsis\n",
        "- Penonton dimungkinkan untuk melihat genre dari sinopsis, untuk memastikan mereka tidak menonton genre yang tidak diinginkan. Contoh, ada beberapa orang yang sangat menghindari film horor\n",
        "- OTT platforms mampu mengkategorikan film dengan lebih akurat, dengan mengklarifikasi sinopsis dengan informasi genre yang diberikan\n",
        "\n",
        "Objektif dari program ini adalah untuk menjadi sarana mengkategorikan film ke genre yang sesuai berdasarkan sinopsisnya, dan diharapkan bisa dipakai oleh berbagai macam pengguna. Model dibuat berdasarkan algoritma Artificial Neural Network (ANN) yang terbaik performanya. Metric yang dipilih untuk menguji performa adalah Accuracy, karena ingin diminimalisir film yang salah diprediksi dan fokus pada model \"correctness\".\n",
        "\n",
        "Program diharapkan selesai per tanggal 19 Maret 2024."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD4WDo2Pw1tg"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2_z6oapw4ck",
        "outputId": "39cfe66b-53b7-4a1f-d5de-46160194c41e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# General use\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Text-related\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords') # Stopwords\n",
        "nltk.download('punkt') # Punctuation\n",
        "nltk.download('wordnet') # Wordnet for lemmatization\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# NN-related\n",
        "from tensorflow.keras.saving import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSIfo7qfwn88"
      },
      "source": [
        "## Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQLZeAibwqnf"
      },
      "source": [
        "### Model loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model yang sudah di-train di-load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E7sR63jlwnHE"
      },
      "outputs": [],
      "source": [
        "# Load trained model\n",
        "model = load_model('model_nlp_final')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I13nJFQHwsA5"
      },
      "source": [
        "### Data loading & processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Di bawah ini, data di-loading dan proses dengan fungsi text_preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FmX3ZOGswybF"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df_inf = pd.read_csv('/content/inference.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show data\n",
        "df_inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QJRKzigxx7Oq"
      },
      "outputs": [],
      "source": [
        "# Pre-processing\n",
        "\n",
        "# Define stopwords\n",
        "stopwords_nltk = list(set(stopwords.words('english')))\n",
        "stopwords_add = ['See full synopsis', 'KBBO-AINOS', 'one',  'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
        "stopwords_all = stopwords_nltk + stopwords_add\n",
        "\n",
        "# Define lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define pre-processing function\n",
        "def text_preprocessing(document):\n",
        "    # Case folding\n",
        "    document = document.lower()\n",
        "    # Number, symbols, punctuations removal (keeping only letters & whitespace)\n",
        "    document = re.sub('[^a-z\\s]+', ' ', document)\n",
        "    # Remove single character if any\n",
        "    document = re.sub(r'\\s+.\\s', ' ', document)\n",
        "    # Whitespace, tabs, new lines\n",
        "    document = document.strip()\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(document)\n",
        "    # Stopwords removal\n",
        "    tokens = [word for word in tokens if word not in stopwords_all]\n",
        "    # Lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Combining Tokens\n",
        "    document = ' '.join(tokens)\n",
        "    return document\n",
        "\n",
        "# Pre-process synopsis\n",
        "df_inf['synopsis_processed'] = df_inf['synopsis'].apply(lambda x: text_preprocessing(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAFLu4q4wm3R"
      },
      "source": [
        "### Predicting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Di bawah ini, data inferens diprediksi dengan model yang sudah di-load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0K-GA7vwP-p",
        "outputId": "526c28e1-7539-4879-f3ba-0395d7e6a075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "Movie genre: Sci-fi\n"
          ]
        }
      ],
      "source": [
        "# Predicting\n",
        "y_pred_inf_proba = model.predict(df_inf['synopsis_processed'])\n",
        "y_pred_inf = np.argmax(y_pred_inf_proba, axis=-1)\n",
        "\n",
        "# Menampilkan hasil prediksi\n",
        "if y_pred_inf == 0:\n",
        "    print('Movie genre: Fantasy')\n",
        "elif y_pred_inf == 1:\n",
        "    print('Movie genre: Horror')\n",
        "elif y_pred_inf == 2:\n",
        "    print('Movie genre: Family')\n",
        "elif y_pred_inf == 3:\n",
        "    print('Movie genre: Sci-fi')\n",
        "elif y_pred_inf == 4:\n",
        "    print('Movie genre: Action')\n",
        "elif y_pred_inf == 5:\n",
        "    print('Movie genre: Crime')\n",
        "elif y_pred_inf == 6:\n",
        "    print('Movie genre: Adventure')\n",
        "elif y_pred_inf == 7:\n",
        "    print('Movie genre: Mystery')\n",
        "elif y_pred_inf == 8:\n",
        "    print('Movie genre: Romance')\n",
        "else:\n",
        "    print('Movie genre: Thriller')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model salah memprediksi data inferens, di mana genre film seharusnya Romance. Namun jika melihat dari sinopsis, memang kurang bisa dipahami bahwa itu adalah genre Romance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
